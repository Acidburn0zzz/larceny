Information about native Larceny on Intel 386-class systems
15 November 2003 / lth


HOW TO BUILD AND USE.

See HOWTO-PETIT for general information about how to use the build
system.  Rather than loading Util/petit-whatever.sch you load one of
these base files:

    Util/nasm-unix.sch
    Util/nasm-win32.sch     (does not yet exist :-)

The system works like Petit Larceny except that it generates source
files in assembly language (to be processed by the NASM assembler)
rather than source files in C.

Obviously you need to have NASM installed on your system.  It is free
and can be downloaded from http://sourceforge.net/projects/nasm.

Technical details are scattered (too much) across Asm/Intel/README and
files in Rts/Intel.


STATUS.

In development.  Generates code that can be compiled to a heap image,
and Larceny can boot this image.  Works at least in part:

  * Loading and running FIB in the interpreter shows no problems.
    Interpreted FIB(30) is about twice as fast as in Petit Larceny.

  * Loading and running REQUIRE works -- can (require 'fortune)
    and get fortunes.

  * Interpreter can rebuild itself and the heap image to bitwise
    identical images!


TODO.

 - implement exception signalling in Rts/Intel/i386-millicode.asm (important)
 - a few FIXMEs in Rts/Intel/i386-instr.asm (unproblematic)
 - a few OPTIMIZEMEs ditto (ditto)
 - twobit needs to be set up with the right number of hardware registers
 - performance (see next section)
 - code size (see section after that)
 - test, test, test


PERFORMANCE.

Programs that do a lot of traps to millicode will likely be slower
than they used to be, because there is more state to save and a more
costly call protocol (one indirect and one direct jump, rather than
just one direct jump).  The operations most likely to suffer adversely
are allocation, the write barrier, and generic arithmetic.  (Of these,
the interpreter heavily relies on allocation and assignment; these
have been fixed and it helps a little, see below.)

The next step would be to (a) compile with profiling, to see if much
time is being spent in the RTS/millicode, and if so where, and (b)
change the assembler to emit debug info that the profiler can use, at
which point we can profile the entire system!

One benchmark is the time it takes to load the compiler from the
interpreter (this should not vary much) and the time it takes to
rebuild the system in the interpreter.

Time it takes to load compiler from source:

Petit Larceny 0.51
  Words allocated: 29204170
  Words reclaimed: 0
  Elapsed time...: 14616 ms (User: 14420 ms; System: 40 ms)
  Elapsed GC time: 461 ms (CPU: 480 in 111 collections.)

Larceny 0.53, with all millicode in C
  Words allocated: 29222154
  Words reclaimed: 0
  Elapsed time...: 10158 ms (User: 9970 ms; System: 30 ms)
  Elapsed GC time: 469 ms (CPU: 440 in 111 collections.)

Larceny 0.53, with a fast pointer check in assembler
  Words allocated: 29222154
  Words reclaimed: 0
  Elapsed time...: 9920 ms (User: 9690 ms; System: 60 ms)
  Elapsed GC time: 466 ms (CPU: 450 in 111 collections.)

Larceny 0.53, with pointer check and faster code for alloc (but not alloci)
  Words allocated: 29222154
  Words reclaimed: 0
  Elapsed time...: 9821 ms (User: 9630 ms; System: 50 ms)
  Elapsed GC time: 468 ms (CPU: 540 in 111 collections.)

Larceny 0.53, as above but with alloci optimized too
  Words allocated: 29222154
  Words reclaimed: 0
  Elapsed time...: 9805 ms (User: 9590 ms; System: 30 ms)
  Elapsed GC time: 468 ms (CPU: 420 in 111 collections.)

Larceny 0.53, as above but with the entire barrier in assembler
  Words allocated: 29222154
  Words reclaimed: 0
  Elapsed time...: 9619 ms (User: 9350 ms; System: 50 ms)
  Elapsed GC time: 461 ms (CPU: 420 in 111 collections.)


CODE SIZE.

 - it is possible that mapping GLOBALS to esp is wrong because all
   loading via GLOBALS will generate a long-form instruction: there
   is not an simple instruction format for esp-indirect fetches, it
   also includes a scale factor (1).  This blows up code size if
   fetching through globals is used much.  It may make sense to make
   millicode calls larger instead.  We can measure the tradeoff.  
   A more reasonable sequence would be to do map CONT to esp and then eg
               mov [GLOBALS+CONT], CONT
               mov CONT, GLOBALS
               call [CONT+X]
   where millicode would need to clean up CONT and not return by
   means of ret but by jumping to the correct address.

OTHER NOTES.

Future ideas:
 - put most-used millicode procs at negative offsets from GLOBALS, so that
   short offsets are generated in calling them.  This reduces code size.
 - nasm can generate .bin format files, ie, raw code.  We can use this to 
   create a system with on-line compilation: just dump the code to an asm 
   file in /tmp, assemble it to a .bin, and slurp the object code into a
   code vector in the heap.  There should be very little extra work involved 
   in getting this done, once the rest works.


--- Local Variables: ---
--- mode: text ---
--- indent-tabs-mode: nil ---
--- End: ---
