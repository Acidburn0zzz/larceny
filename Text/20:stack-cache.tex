\input{larceny.sty}
\textheight 9in

\title{Larceny Note \#20: \\
       A Scheme for Fast and Adjustable Stack Caches}
\author{Lars Thomas Hansen}

\begin{document}
\maketitle

\begin{abstract}
Some languages have first-class continuations, the efficient implementation
of which requires some cleverness.  Several strategies have been proposed; we
describe a particularly efficient implementation of the so-called
incremental stack/heap strategy.  Our implementation makes the heap double
as a stack cache and is only suitable for systems which use a copying
garbage collector.

While the main advantages of our scheme are a particularly efficient stack
cache flush; reduced memory waste; and an opportunity for better hardware
cache locality, it also leads to a slew of simplifications in our Scheme
system, Larceny. As another added benefit, the size of the stack cache does no
longer have to be fixed; rather, the stack cache can be resized dynamically
at no cost.
\end{abstract}

\section{Introduction}

The efficient implementation of languages which incorporate first-class
continuations, of which Scheme \cite{IEEEscheme} is one, often relies on the
use of a {\em stack cache}. The stack cache behaves like a regular stack
except that it is bounded; it may therefore overflow. When such an overflow
occurs, the stack cache is copied into the heap and transformed into a chain
of individual frames in the process. The cache is reused for new frames.
Eventually, as procedures return, the stack cache will underflow, and old
frames will have to be fetched from the heap and back into the stack cache.

When a continuation is captured, the system behaves similarly: the stack
cache is flushed, and the continuation object is simply the resulting chain
of frames in the heap, including any frames which were already in the heap
before the flush.  

This strategy for the management of stacks is known as the ``incremental
stack/heap'' strategy, and is described by Clinger \cite{Clinger:isfc}.

A simple implementation of this scheme puts the stack cache in an area of
memory which is separate from the heap, and copies the frames from the stack
into the heap when the stack is flushed, as outlined above.

However, this simple implementation may not be the best. Some systems, like
Larceny, will flush the stack cache when the garbage collector is invoked,
because this simplifies the garbage collector -- there is no longer any need
to scan the stack. This means that there has to be space left over in the
heap when the flush is done so that we can guarantee that the heap will not
overflow during the flush. Much of this extra space will be wasted if the
stack cache is not nearly full at the time of a collection. In addition,
copying the stack into the heap takes time.

Second, there can be performance advantages to keeping the most
frequently-accessed memory together, as (hardware) cache locality is
improved. In a system with generational garbage collection, the most
frequently accessed memory is the ephemeral (new) generation and the stack
cache. However, the ephemeral generation is usually split into an oldspace
and a newspace, and careful placement of the stack cache in relation to
these two areas is therefore necessary to get good locality.

Finally, the size of a stack cache is fixed. One can make provisions to grow
it at run-time, but this is not easy in a high-performance system.  It may
seem peculiar that one would like to grow it in the first place (after all,
why could one simply not make the cache larger in the first place), but 
there is no benefit in needlessly flushing the cache if a continuation is
not going to be captured, and a stack cache which behaves more like a stack
may be desirable.\footnote{Research topic...}

We therefore propose a new implementation of the incremental stack/heap
strategy which reduces the cost of a stack flush, and which also has other
desirable benefits.  In our scheme, the stack cache is kept in the top part
of the current ephemeral area, and a stack frame has approximately the same
layout as a heap frame.  When the time to flush the stack cache comes, the
stack flush procedure simply walks the stack and transforms each stack frame
to a heap frame in-place. The stack cache is then logically moved further
down into the ephemeral area, beyond the top of the just-flushed cache, and
execution continues.

The advantages of this scheme are numerous. First, flushing is cheap and has
good locality.  Second, the stack cache is not bounded; it can use as much
of the ephemeral area as is available at any moment, and the overflow will
occur only when the entire ephemeral area is full. The only time the cache
is flushed and the ephemeral area is not full is when a continuation is
captured. Third, since the stack limit is the same as the ephemeral heap top
pointer, and the latter is usually in a register anyway, stack overflow
testing is faster, and allocation is either faster (because the heap limit
used to be in memory) or we save a register (because the heap limit used to
be in a register, but it is no longer needed). Fourth, since the ephemeral
area now contains most of the frequently-used memory, it is simple for us to
tune its size to fit the hardware cache size.  Fifth, no memory is wasted in
the ephemeral area, because no overflow area is necessary.  Finally, the
stack flush logic is made simpler because stack frames look approximately
right in the first place, and there is less work to do (and fewer
opportunities to make a mistake). A consequence of this is that it is now
reasonable to write the stack handling logic in assembly language rather
than in C, resulting in further performance improvements.

There are also some disadvantages to this method. First, the parts of the
system which set up a stack frame need to know what the heap frame looks
like; however, it's just a change from one format to the other, so this
inconvenience is minor. Second, the stack cache and the ephemeral area are
allocated together, and the maximum size of each is constrained by the size
of the other at any given moment.

Section 2 presents the method in detail as it is implemented in Larceny.
Section 3 presents some measurements on representative programs. 

\section{Details of the Implementation}

We now describe how our scheme is implemented in Larceny.

% in particular, a stack frame is at least as large as a heap frame. 

In Larceny, a heap frame is represented as a vector with the following
layout: element 0 is the dynamic link to the previous frame, element 1 is
the return address represented as an offset into the procedure for this
frame, element 2 is the procedure, and the rest of the elements are saved
registers and/or temporaries. In addition, there is a vector header
which holds a type tag and the size of the vector:

\begin{minipage}{\linewidth}
\begin{verbatim}
        0sss ssss ssss ssss ssss ssss tttt tttt    header
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    ptr to previous frame
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    return address
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    procedure (saved REG0)
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    saved REG1
        ...
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    saved temporary
        ...
\end{verbatim}
\end{minipage}

A stack frame, on the other hand, is a little different. The first word is
the size of the frame. The second word is reserved and is not initialized
when the frame is created. The third word contains the return address,
represented as a pointer into the code vector for the procedure. The fourth
word is the procedure. The rest contain saved registers and/or temporaries.

\begin{minipage}{\linewidth}
\begin{verbatim}
        ssss ssss ssss ssss ssss ssss ssss ssss    size
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    reserved
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    return address
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    procedure (saved REG0)
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    saved REG1
        ...
        xxxx xxxx xxxx xxxx xxxx xxxx xxxx xxxx    temporary
        ...
\end{verbatim}
\end{minipage}

When a frame is converted from a stack frame to a heap frame, the size field
of the frame is converted to a vector header, the reserved word is
initialized to point to the previous frame in the chain, and the return
address word is converted from a pointer into the code vector to an offset.
Altogether, this conversion involves four loads and three stores regardless
of the size of the frame, and cache locality is excellent. In contrast, a
frame copy would take at least 5 loads and 4 stores, and typically more, as
few frames are of minimal size.\footnote{We should figure out what the
average frame size in Larceny is. This should be simple.}

Larceny also keeps a dummy frame at the bottom of the stack cache to catch
underflows without doing any underflow checking. Therefore, when we have
flushed the stack cache, and after every garbage collection, we must set up
a new dummy frame at the new location of the stack cache. It is not
necessary to get rid of the old dummy frame; it will never be seen by the
collector because it is not part of the chain of frames in the heap. Notice
that setting up the new dummy frame and moving the stack cache base pointer
is all the work it takes to move the stack cache.

Allocation now becomes very simple. We can allocate memory as long as we
don't move the heap top pointer {\sc e\_top} past the stack pointer {\sc stkp}.
A major benefit (on the low level) is that we save a register: the heap limit
pointer does no longer need to be kept around.

To create a stack frame is equally easy. We cannot create the frame if {\sc
stkp} goes below {\sc e\_top}; this is much faster to determine than the
previous scheme where the stack overflow limit was kept in memory and had to
be fetched all the time. If the stack does not overflow, then allocation
proceeds by setting up the stack size and initializing the data slots (and
saving the return address, if required). A problem is that it is sometimes
useful to set up a minimal stack frame for bookkeeping; the space used by
the current dummy frame can be used for this if necessary.

\section{Performance}

\section{Conclusions}

\end{document}
