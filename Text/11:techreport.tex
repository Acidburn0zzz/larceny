% -*- TeX -*-
%
% Technical Report on the design of Larceny

\documentstyle[10pt,tr]{article}  % uses UofO techreport style sheet
\topmargin      -2.0cm
\oddsidemargin   0.0cm
\evensidemargin  0.0cm
\textwidth       6.5in
\textheight      9.0in
\parindent       0.0cm
\parskip         0.4cm

\title{Larceny: Scheme on the SPARC}
\author{Lars Thomas Hansen\thanks{This research was supported in part
by OACIS grant such-and-such.}}

\begin{document}
\titlebox
\begin{abstract}
This line is there for the benefit of a clean run thru \LaTeX and will go away
when we get a real abstract...
\end{abstract}
\pagebreak

\section{Introduction}

``Larceny'' is a run-time system for IEEE Scheme \cite{IEEEscheme} on the
SPARC \cite{SPARC} architecture. The system was designed and implemented
primarily to support our research into advanced implementation techniques
for Scheme, including type and representation inference, fast generic
arithmetic, and simple and efficient garbage collection. The current version
of the system runs on Sun SPARCstation machines under SunOS UNIX.

Throughout the design and implementation of the system, the two overriding
concerns have been performance and simplicity. In particular, it has been
our goal that our system should be as fast as or faster than all other LISP
and ML systems available for the SPARC architecture; it is our belief that
our results are valid only if obtained through the use of such a high
performance system.  Simplicity has been important both in obtaining
performance and in itself: we have limited resources, and simplicity in the
design simplifies the implementation and debugging work, letting us get on
with more important tasks.

The factors which contribute the most towards performance are:
\begin{itemize}
\item the calling conventions;
\item the data structure layout, including the tagging scheme;
\item the memory management system; and
\item the generic arithmetic implementation.
\end{itemize}
Of course, the compiler technology is also important, but it is not a topic
of this report.

Section \ref{SparcSection} gives an overview of the SPARC architecture, and
section \ref{DesignParametersSection} discusses some basic considerations
which affect our implementation.  Sections \ref{CallingSection} through
\ref{GenericSection} discuss the four issues listed above.  Section
\ref{BenchmarksSection} presents some results from benchmarking the current
version of our system, and section \ref{ConclusionSection} concludes the
report by summarizing what we have achieved and what remains.

\section{The SPARC Architecture}
\label{SparcSection}

The SPARC \cite{SPARC} architecture is a fairly typical representative of
modern RISC microprocessors. It is a load/store architecture with only two
addressing modes (register+immediate and register+register); a
general-purpose register set of 32 registers, one of which is always 0;
a separate floating-point unit with its own register set; delayed branches;
and a small and regular instruction set. 

The SPARC stores condition codes in a special status register in the
processor.

In addition to the features listed above, the SPARC architecture
incorporates register windows\cite{someone}. The function of register
windows is to provide a
means of cheap continuation frame allocation and deallocation. A procedure
sees a window of 24 of the processor's registers, and uses these as its
working registers. Parameters are passed to other procedures in a
subset of this window known as the {\em out} registers. A called procedure
will request the allocation of a new window of registers; when it does this,
it will see the {\em out} registers of the caller as its own {\em in} 
registers, in which it expects to find its parameters.

(overflow, underflow, and stuff)
(global registers)
(only integer regs are windowed)

SPARC instructions can be classified as integer instructions (working on the
general-purpose integer registers), memory instructions (loads and
stores), or floating-point instructions. Branches are considered integer
instructions, as are instrutions manipulating the register windows.

On most implementations of the architecture, integer instructions (with the
exception of multiplication and division, to the extent they are implemented
in hardware at all) complete in one clock cycle; memory instructions
complete in two or more cycles; and the performance of floating-point
instructions is unknown.

(tagged arithmetic)
(what Sun did wrong with the non-trapping versions)
(branch timings on SS1 class machines)

\section{Basic Design Parameters}
\label{DesignParametersSection}

%- share the MacScheme compiler and library
%	- some low-level compatibility is nice
%	- compiler does not go below abstract machine level
%- software interrupts
%	- software timer
%- fast call/cc

Some of the restrictions\footnote{``Restrictions'' not necessarily meaning
that these conditions created problems, but rather that they preempted some
design decisions.} on the projects were the following.

The compiler used is the MacScheme version 4 compiler (known as the
``Twobit'' compiler); it generates code for the MacScheme abstract machine,
which is a medium-level bytecode-oriented instruction set for an accumulator
machine with a set of data registers. Larceny takes the
output of the compiler and generates SPARC assembly language.


\section{Calling Conventions}
\label{CallingSection}

%- proper tail-recursion
%- save/stack setup
%- invocation
%- why stack allocation is better than heap allocation for stack frames
%- stack cache to support fast call/cc

\section{Data Structure Layouts and Tag Scheme}

Larceny provides a small set of basic data representations and implements
most Scheme data types in terms of the basic representations. A small set of
basic types simplifies the garbage collector, but may increase memory
consumption slightly because the sharing of data is more limited than in
other systems with more complex representations. For example, some systems
allow pointers into the middle of data structures; Larceny does not.

\subsection{The Basic Types}

There are six basic data types: fixnums, other immediates, pairs, vector-like
structures, bytevector-like structures, and procedures. Tags are kept in the
low three bits of a word:

\begin{minipage}{\linewidth}
\begin{verbatim}
  xxxx xxxx  xxxx xxxx  xxxx xxxx  xxxx xx00   fixnum
  xxxx xxxx  xxxx xxxx  xxxx xxxx  xxxx xx10   immediate
  pppp pppp  pppp pppp  pppp pppp  pppp p001   pointer to pair 
  pppp pppp  pppp pppp  pppp pppp  pppp p011   pointer to vector struct
  pppp pppp  pppp pppp  pppp pppp  pppp p101   pointer to bytevector struct
  pppp pppp  pppp pppp  pppp pppp  pppp p111   pointer to procedure struct
\end{verbatim}
\end{minipage}

Notice that in the case of fixnums and immediates, the high bit of the tag is
also the low bit of the datum itself. This is not critical for immediates,
but it matters a great deal for fixnums: with a two-bit tag for fixnums
which is 00, we get 29-bit signed fixnums and we can also use the tagged
arithmetic instructions provided by the SPARC architecture.

Since all pointers use 3-bit tags, objects must be aligned on 8-byte
boundaries. Keeping the tags in the low bits of a word results in the very
nice property that tags need not usually be stripped before a dereference;
the offset can be adjusted for the tag with no additional
penalty.\footnote{This is true on the SPARC and probably on most RISC
architectures but may not be true in general. Consider fetching from an
offset 0 which adjusted for a pair tag becomes offset -1; some CPUs have
fast addressing modes for 0-offset but will require an immediate constant
for non-zero offsets.}

Immediates are used for odd data around the system. The following are
the immediate formats:

\begin{minipage}{\linewidth}
\begin{verbatim}
  0000 0000  0000 0000  0000 0000  0000 0010   #f
  0000 0000  0000 0000  0000 0000  0000 0110   #t
  0000 0000  0000 0000  0000 0000  0000 1010   empty list
  xxxx xxxx  xxxx xxxx  xxxx xxxx  0001 0110   miscellaneous
  0000 0000  cccc cccc  0000 0000  0010 0110   character
  0sss ssss  ssss ssss  ssss ssss  100x xx10   reserved header
  0sss ssss  ssss ssss  ssss ss00  101x xx10   vector-like header
  0sss ssss  ssss ssss  ssss ssss  110x xx10   bytevector-like header
  0sss ssss  ssss ssss  ssss ss00  1111 1110   procedure header
\end{verbatim}
\end{minipage}

The "s" bits contain the size of the data structure in bytes, not
including the header word, and not including padding (see below). The
collector will correctly round "bytevector" and "reserved" lengths up
to a word boundary. Hence, for these structures, the "s" bits give the
correct length of the datum, like the length of a string.

Since all pointers are doubleword-aligned, some vectors, bytevectors,
and procedures will have to be padded out to an even number of words.
The mutator must allocate the extra word but may choose to leave it
uninitialized; the collector will take the size of the vector into
account and skip the padding. If the word is initialized, it may or
may not be copied along with the structure during a collection.

The various non-immediate data have the following layouts:

\begin{itemize}
\item
Pairs: A pair has two words, the car (low word) and the cdr (high word).
The pair pointer points to the car of the pair.

\item
A vector-like structure has the header word in the low position, followed
by tagged words in all locations of the vector. The vector pointer
points to the header word.

\item
A bytevector-like structure has the header word in the low position,
followed by untagged bytes in all locations of the vector. The bytevector
pointer points to the header word.

\item
A procedure structure has the header word in the low position, followed by
tagged pointers in all locations of the procedure structure. The procedure
pointer points to the header word.
\end{itemize}

With the exceptions of the header and the pointer tag, a procedure looks
just like a vector-like structure. While procedures could be represented
using vector-like structures, there are performance advantages to having a
distinguished tag, and with procedures being so common, this is a worthwhile
optimization despite the extra complexity.

\subsection{An Example: {\tt vector-ref}}

With the outlined structures, the code for a general {\tt vector-ref} is 
the following, assuming that the (assumed) vector pointer is in REG1,
that the index is in REG2, and that the result is to be stored in REG3.

\begin{minipage}{\linewidth}
\begin{verbatim}
        and     %REG1, TAGMASK, %TMP0           ! pointer tag
        cmp     %TMP0, VEC_TAG
        be,a    L1                              ! branch if ok tag
        ld      [ %REG1 - VEC_TAG ], %TMP0      ! header
L0:     ! fault handling code goes here
        ...
L1:     and     %TMP0, 0xFF, %TMP1              ! header tag
        cmp     %TMP1, VEC_HDR
        be,a    L2                              ! branch if ok header
        srl     %TMP0, 8, %TMP1                 ! size field
        b       L0                              ! bogus header
        nop
L2:     tsubcc  %TMP1, %REG2, %g0               ! checking index
        bvs     L0                              ! not a fixnum
        nop
        bgu,a   L3                              ! jump on if within range
        sub     %REG1, 4-VEC_TAG, %TMP1         ! strip tag + adjust
        b       L0                              ! bogus index
        nop
L3:     ld      [ %TMP1 + REG2 ], %REG3         ! fetch word...
\end{verbatim}
\end{minipage}

The code is as fast as possible, although it could possibly be made a trifle
smaller at some expense in speed; on newer SPARCstations, where the cost of
an untaken branch is the same as the cost of a taken branch, the tradeoffs
change a bit. With the above code, a {\tt vector-ref} takes 16 clocks
assuming that both loads hit the cache.

\section{Memory Management}

Memory management can be further subdivided into memory allocation and memory
reclamation. We shall discuss the latter first and return to memory allocation
afterwards.

\subsection{Garbage Collection}

On of the major advantages of using a higher-level programming language like
Scheme is the availability of automatic memory reclamation or {\em garbage
collection}. The LISP and SmallTalk communities have spent much effort on
making automatic garbage collection efficient; a good survey paper is 
\cite{someoneelse}. Essentially, collectors are either copying
or non-copying, and the class of copying collectors can be further
subdivided into generational and non-generational collectors. Hybrid
approaches are also in use.

Larceny uses a simple version of Ungar's generation scavenging garbage
collector\cite{Ungar:gsgc}, which in turn is based on the work of Lieberman
and Hewitt\cite{LiebermanHewitt}. Interesting questions about garbage
collectors include: ``What does memory look like?'', ``When do we
collect?'', and ``What do we collect?''.

\subsubsection{What does memory look like?}

In Larceny, memory is divided into four areas: the {\em stack cache}, 
the {\em static area}, the {\em tenured area}, and the {\em ephemeral area}:
\begin{itemize}
\item
As explained in section \ref{StackCacheSection}, the stack cache is used for
the quick allocation and deallocation of continuation frames. With the
exception of the stack pointer, there are no pointers in the system pointing
into the stack cache (although there are pointers out of it).

\item
The static area holds system code and data which will not change at run time
and which consequently will never become garbage. There are no out pointers
from the static area, and assignments into objects in this area are illegal.

\item
The tenured area holds objects which have survived at least one garbage
collection, and which are expected to be live for a while. Objects in
the tenured area got into this area by being moved here from the ephemeral
area.

\item
The ephemeral area holds all newly-allocated objects as well as objects
which have survived a few garbage collections but which have not yet been
tenured.
\end{itemize}

There may be pointers from the tenured area into the ephemeral area and vice
versa, and objects in both areas may be changed by means of assignment.
There may be pointers from both of these spaces into the static area.

In addition, both the ephemeral and the tenured areas are split into an
oldspace and a newspace, and garbage collection in both areas are of the
copying kind, using Cheney's algorithm \cite{Cheney} for nonrecursive
copying.

(Using a copying collector in the tenured area is possibly the wrong thing: it
wastes much memory (as the tenured area can get quite big, and we need to
have an equal-sized newspace around), and it complicates somewhat the dynamic
expansion of the tenured area. Since the tenured area gets collected rarely,
we could go with a slower collector which does not have these problems.)

The stack cache is always empty during a collection; if necessary, the stack
is flushed to the heap before the collection.

\subsubsection{When do we collect?}

A garbage collection is triggered when the allocation of an object in the
ephemeral area fails because there is not neough space left in the ephemeral
area. The default collection type is an {\em ephemeral 
collection}\/:
live objects in the ephemeral oldspace are copied into the ephemeral newspace.
However, if, after an ephemeral collection, the ephemeral area contains
enough live objects to fill the area beyond a certain limit, then the next
collection
will be a {\em tenuring collection}, in which all live objects in the ephemeral
oldspace are copied into the tenured oldspace. If, after such a tenuring 
collection the tenured area is nearly full, then the next collection will be
a {\em full collection}, in which all live objects are copied into the tenured
newspace.

The preceding paragraph also implies our tenuring policy: an object is
tenured if and only if it is live during a tenuring or full collection;
these collections are triggered only when the number of live objects in the
system reaches some limit. Hence, an object's age has little bearing on
whether it is tenured or not (although all tenured objects have survived at
least one collection).

A collection is also triggered when the transaction list (discussed next)
meets with the tenured data area.

\subsubsection{What do we collect?}

The chief problem in garbage collection is to guarantee that all objects
which were live before a collection are live after as well. This can be
guaranteed if we can find the set of all {\em root pointers}; the root
pointers are exactly those which, if followed, transitively will reach all
live objects. [NEEDS WORK.]

In Larceny, all root pointers are kept in the (virtual) machine registers and
in a small set of additional global variables. In addition, during an ephemeral
collection it is necessary to consider as roots all those objects in the
tenured area which have pointers into the ephemeral area, as these pointers
may be the only ones to the ephemeral objects, and in any case the pointers
will need to be adjusted since the objects they point to are moved.

There are no roots in the stack cache, as the stack is flushed to the heap
before a collection.

Several methods immediately present themself for making sure that roots
in the tenured area are
found. The first method is to scan the entire tenured area during an
ephemeral collection, looking for pointers into the ephemeral area, and
copying the objects which are pointed to. This method may suffer from poor
performance in the presence of virtual memory. [CITE SOMEONE]

Two other methods depend on the observation that the only way an object
in the tenured area can point to an object in the ephemeral area is if the
former object has been changed by an assignment. The second method is 
therefore to keep track of those objects in the tenured area which have been
updated with pointers into the ephemeral area. The third method is a slight
variation on this: we keep track of the individual locations of the objects
in the tenured space which hold pointers into the ephemeral space.

Larceny and Ungar's Generation Scavenger both use method two. In our case,
keeping a list of object pointers is a win in terms of simplicity, as
pointing into the middle of objects have peculiar semantics. Method three
may be slightly more efficient since the collector can go straight to the
root (the entire object does not need to be scanned). Our collector 
incorporates an optimization which avoids scanning an object more than once:
a bit in the object header is set when the object has been scanned for
roots. Also, keeping object pointers saves space in the presence of many
roots within an object, since only one pointer need to be kept. We compact
the list of objects with roots during a collection (again using the bit in
the header) and end up with a minimal list of root objects.

Other schemes for keeping track of potential roots in the tenured area have
been proposed; we mention specially Wilson's card-marking scheme.
\cite{Wilson:card-marking}

In Larceny, the object list (called the {\em transaction list}) is
maintained as a contiguous area of object pointers at the high end of the
Tenured area, growing toward lower addresses. An object is pointer is added
to the list whenever an assignment is made into an object in the tenured
area and the assigned value is a pointer into the ephemeral area.

Side effects are now more expensive than a simple store into memory because
we have to check to see whether the assigned-into object resides in the
Tenured area, and, if so, if the assigned value is a pointer into the
ephemeral space, and, if so, a transaction must be recorded, which in turn
means checking for overflow of the tenured area.  Exactly how this cost
affects execution time of interesting programs is the topic of the author's
forthcoming Master's Thesis and will not be speculated upon here.

\subsection{Memory Allocation}

Larceny currently uses a straightforward method for memory allocation: if
there is room for the object, allocate it, else call the collector and
try again. Since heap pointers are kept in registers, there is no memory
traffic save for the initialization of the object, and allocation is cheap.
One can, as Appel\cite{Appel} points out, do better by using the memory
management hardware to trap allocations which overflow the heap. Since
Larceny only uses two more clocks to do a ``cons'' than what is achievable
by using Appel's trick, we have not found it worthwhile to explore this
possibility. If the trap can be handled in a reasonable amount of time,
however, it may be reasonable to incorporate this hack at least in order
to check for stack overflows. Anyway, in the presence of imprecise traps,
this method for overflow detection is less attractive\cite{AppelLi}.

The best we can do for a general ``cons'' of {\tt \%RESULT} and {\tt \%REG3}
is this:

\begin{minipage}{\linewidth}
\begin{verbatim}
        st      %RESULT, [ %E_TOP ]          ! store CAR optimistically
        add     %E_TOP, 8, %E_TOP            ! allocate optimistically
        cmp     %E_LIMIT, %E_TOP             ! check overflow
        st      %REG3, [ %E_TOP - 4 ]        ! store CDR
        bgt,a   L1
        sub     %E_TOP, 8-PAIR_TAG, %RESULT  ! make resulting pointer
        jmpl    %MILLICODE + M_CONS, %o7     ! collect and then cons
        mov     %REG3, %ARGREG2
  L1:
\end{verbatim}
\end{minipage}

The above code assumes that we it is legal to write above the heap top
as long as the written data can be discarded. Larceny guarantees that
this heap condition holds.

Appel's best code (assuming automatic trapping of overflows) is this:

\begin{minipage}{\linewidth}
\begin{verbatim}
        st      %RESULT, [ %E_TOP ]          ! store CAR; may trap
        add     %E_TOP, PAIR_TAG, %RESULT    ! make resulting pointer
        add     %E_TOP, 8, %E_TOP            ! allocate
        st      %REG3, [ %E_TOP - 4 ]        ! store CDR
\end{verbatim}
\end{minipage}

\section{Generic Arithmetic}
\label{GenericSection}

\section{Some Benchmarks}
\label{BenchmarksSection}

\section{Conclusion}
\label{ConclusionSection}

\pagebreak
\begin{thebibliography}{99}

\bibitem{Appel}
Andrew W. Appel, {\em Simple Generational Garbage Collection and Fast 
Allocation}. Software -- Practice and experience, Vol 19(2), pp 171-183.

\bibitem{AppelLi}
Andrew W. Appel and Kai Li, {\em Virtual Memory Primitives for User Programs}.
Proceedings of the Fourth International Conference on Architectural Support
for Programming Languages and Operating Systems (ASPLOS-IV), pp 96-107.

\bibitem{Cheney}
C. J. Cheney, {\em A Nonrecursive List Compacting Algorithm}.
CACM Volume 13, Number 11 (November 1970), pp 677-678.

\bibitem{IEEEscheme}
{\em IEEE Std 1178-1990}, IEEE Standard for the Scheme Programming Language.

\bibitem{LiebermanHewitt}
Henry Lieberman and Carl Hewitt, {\em A Real-Time Garbage Collector Based
on the Lifetimes of Objects}. CACM Volume 26, Number 6 (June 1983), pp 419-429.

\bibitem{SPARC}
SPARC International, {\em The SPARC Architecture Manual, Version 8}.
Prentice-Hall, Englewood Cliffs, NJ, 1992.

\end{thebibliography}

\end{document}

